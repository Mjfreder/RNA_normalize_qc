# RNA_normalize_qc
Pipeline for processing RNA bulk count data to normalize, globally re-center, detect technical outliers, and QC GC-bias
Installation steps:
I. Open a terminal in VS code and install PDM tool: pip install pdm
1) Verify installation: pdm –version
2) Create a folder called “RNA_process_QC”
3) Copy and paste the 8 python programs inside the RNA_process_QC folder or create new python files within the folder and paste text code from below, being careful to name them as above
4) Open a new terminal within the RNA_process_QC folder using VS code
5) Create a virtual environment inside PDM to install Python 3.11 : pdm venv create -p python3.11
5) Create a project by typing the command in the terminal: pdm init
6) Follow PDM prompts and enter optional information or hit enter for default selections
7) Add the following dependencies one at a time using the command : pdm add “fill in name of dependencies” to make sure each is successfully installed:
pdm add pandas
pdm add numpy
pdm add scipy
pdm add statsmodels
pdm add fpdf
pdm add matplotlib
8) Create a subfolder inside “RNA_process_QC” called “Count_inputs”
9) Paste RSEM output files for data to be normalized together as separate files inside the “Count_inputs” subfolder.
10) Run the filename1.py code to generate a csv file where all file name prefixes are extracted from the “Count_inputs” folder and outputted to a text file called “file_names.txt”.  To run enter: pdm run filename1.py
11) Open the file_names.txt file in Excel. Open a new blank worksheet file in Excel and create two column headers by pasting in “File Id” and “Sample ID” being sure to adhere to the exact same font and punctuation shown here.
12) Copy the text with filenames from file_names.txt and paste underneath the column labeled “File Id”.  In the corresponding row of the adjacent column labeled “Sample ID” type in the short name you want to use to identify samples. Save the file with the exact name “File_ID_sample_ID_map” in Excel but use the dropdown menu to save as a csv file. Final name will be File_ID_sample_ID_map.csv if the show extensions option is activated in Windows Explorer.
13. Use excel or a text editor to open an example file of the RSEM outputs (we recommend a program called Delimit on windows OS for conveniently viewing any type of .txt, .csv, or . tsv file). Ensure that the RSEM output has the following typical headers with exact syntax: “gene_id”, “effective length”, “expected_count”. Other columns will be ignored by the program. If the count files from samples has already been merged, see information below and skip steps #-#
14. Take note of what kind  of gene id the files are using and whether it is an ensemble ID (e.g., ENSG….), an Entrez ID (i.e., 1021, etc..), or an actual gene symbol in the column.
15. Using information listed in from Supplementary Table S4 to create a file called “gene_reference.csv”. Open a new worksheet file in Excel.  In the first row of the first column type exactly “gene_id”. Using TableS4 copy and paste the gene IDs that match those used in the count files. If the count file gene_ids are Ensemble IDs with version numbers after a period, the program still works fine with entering them without the version in the “gene_reference.csv” file because the code automatically edits drops the version characters. If the gene IDs in the count files are Entrez IDs they appear as integers and just copy the integer gene IDs from Table S4. Create a second column in the gene_reference.csv file called “Symbol” and paste the corresponding gene symbols from Table S4 that align with values in the gene_id column.  Use the save as command to save the Excel file as a “.csv” which automatically is added to the file name “gene_reference” which should be used.
16. In the VS code  prompt within the RNA_Process_QC folder type : pdm run count_merger6.py. An output called “combined_data.csv” is created which merges expected counts, effective lengths, and includes columns with the short/custom names for samples extracted from the File_ID_sample_ID_map.csv file.  
17. If the merged or meta file of count data from individual files already exists then steps #8-16 can be ommitted, but the combined_data.csv must be generated by correctly reformatting the metadata so that the first column is a header called “gene_id” which has the gene IDs listed, and subsequent columns should appear in a triplet pattern corresponding to each sample with headers of “Sample_ID”, “effective_length”, and “expected_count”. All rows underneath the “Sample_ID” column should contain the desired Sample ID string text repeated all the way down. Values in the effective length column should correspond to the gene sizes in base pairs, and the expected counts column should contain the numerical value for counts. If the RSEM method was not employed, raw counts can be used in place and fixed gene sizes should be used.
18. To run the normalization program, make sure the gene_reference.csv file created before is still in the directory and is closed (can be accessed by the program). Type and enter: pdm run normalize45.py
Many outputs are generated as explained in the readme information below. The output called “final_adjusted_log2_fpkm_uq.csv” contains log2  transformed  upper quartile normalized count data that will be used as in input for the GCplotQC program.  The output “step18_log2_to_linear.csv” contains the upper quartile normalized count data transformed back to linear space after substituting 0 for negative log2 values, and will automatically be read as input for the convert to GC code.
19. To create a .gct file in linear space for gene set enrichment analysis, type and enter: pdm run convertGCT.py
20. To run the GC QC steps in the pipeline, it is necessary to supply two additional input files. First, create a csv file with the first header spelled and formatted exactly as “Symbol” and a second column with a header formatted and spelled as “Reference” which should be populated with the average log2 gene expression values from the the cohort to be used for comparison as a standard (e.g. TCGA data or cohort average). For best usage the average gene expression values from the reference cohort should be derived using the same normalization protocol here, which globally rescales the data to have a median =7 in log2 space. Alternatively, if no standard reference expression data is available, the experimental cohort average values could be used. The file should be saved as “Reference_ave.csv”. The second additional input file should be named “Gene_GC.csv” which should have the first column header labeled “Symbol” and the second column header labeled “% GC” formatted exactly as it appears here. Rows in the first column should contain gene symbols spelled and formatted the same in the “Reference_ave.csv” and “Gene_GC.csv” file and should match the gene symbols present in the normalized output file  “final_adjusted_log2_fpkm_uq.csv” and in the gene_reference.csv file used earlier in the pipeline. The first part of the program is a subroutine called “generate_plot_csv.py” that does not need to be run separately but combines information from the “final_adjusted_log2_fpkm_uq.csv”, “Reference_ave.csv”, and “Gene_GC.csv” files to create the needed input file called “Plot.csv”.  The “Gene_GC.csv” file supplied with this manuscript can be used and contains the %GC values derived from canonical transcript IDs of known protein coding genes. If customization is desired, the % GC values can be substituted to correspond to values calculated from any non-canonical transcripts such as the most abundant transcript in a cohort if that is known.  Once the necessary input files are saved in the main folder “ RNA_Process_QC” the program can be run using the command: pdm run GC_plotsQC.py . The program generates the needed input file Plots.csv as well as png files for every smoothed curve plotted along side the smoothed curve derived from whatever is chosen as a reference.  The area between the reference curve and point along the sample curve that area beneath the reference curve is calculated for each sample and overlayed on the plots along with their sample names. Additionally, a table called “area_below_reference.csv” is generated that lists all sample IDs alongside the area between the sample and the reference curve, for easy reference. An aggregate PDF file of all the graphs is also generated and outputted as “spline_plots.pdf”.  Note: any gene symbols that do not appear in all 3 input files are automatically filtered out by the program and appear in a separate output as a list in the text file called “dropped_genes.txt”.
21. The program to detect true gene dropout (not to be confused with dropped_genes” from step 20 above) is called “zeroes.py”. To run this program, only one input file is needed but must be manually created. The required input file is called “zeros.csv” and must contain the following column headers in order “Symbol”, “Observed_zeros”, “Total_samples”, and “Probability”. Rows under “Symbol” should contain the gene symbols and “Total samples” should contain the total number of cohort samples being used to calculate how many samples had an observe zero for a gene, which should exclude outliers.  For each gene, manually sum the number of cohort samples for which the gene expression value from the output “step4_fpkm_uq.csv” containing counts was exactly equal to 0, before any 0 values are substituted later for all normalized log2 values (e.g., any file including step15a or later). Therefore it is imperative to use files before step15a when negative log2 values are replaced.  The number of samples with “true 0” should be entered in the column labeled “Observed_zeros”. The probability values entered in the rows underneath the column header titled “Probability” must be externally calculated from some reference cohort, such as TCGA data.  Here it is okay to use raw TCGA count data to identify true zeros, or again if TCGA is run through the pipeline simply use data in the “step4_fpkm_uq.csv” file for calculating probability.  The probability formula is equal to the number of reference samples with true  zero divided by the total number of samples considered in the reference cohort and should be a fraction ≤ 1.  Once the needed input files are saved in the main folder “RNA_Process_QC” simply type and enter: pdm run zeroes.py.  This generates an output called “Zeros_with_P_values” that adds columns with raw P-values and Benjamini-Hochberg adjusted P-values.

Filename1.py
Overview
This script extracts file names from a specified folder and saves them into a text file. It processes files inside a folder named "Count_inputs" located in the same directory as the script. The output file contains only the base names of the files (excluding extensions).
Input Files
This script does not require specific input files, but it processes all files found inside the "Count_inputs" folder.
Folder Structure
Folder Name: Count_inputs
Contents: Any number of files with various extensions (e.g., .csv, .txt, .xlsx)
Processing Steps
The script checks if the folder Count_inputs exists.
It retrieves a list of all files inside this folder.
It extracts the base file name (removing the extension) for each file.
The processed names are written to an output text file.
If the folder does not exist, an error message is displayed.
Output Files
File Name: file_names.txt
Contents: Each line in the file corresponds to the base name (prefix) of a file found in the Count_inputs folder.
Example output:
sample1
dataset_A
experiment_results
If the original files were sample1.csv, dataset_A.txt, and experiment_results.xlsx, only their base names are stored.
Error Handling
If the Count_inputs folder does not exist, an error message is printed:
The folder path <path> does not exist. Please check the path and try again.
If any unexpected error occurs, the script displays:
An error occurred: <error message>
Usage
Ensure the Count_inputs folder is located in the same directory as the script.
Run the script in a Python environment.
The output file file_names.txt will be generated in the script's directory.
Dependencies
This script uses only built-in Python libraries (os). No additional dependencies are required.
Notes
This script does not modify or move any input files; it only reads their names.
The output file is overwritten each time the script runs.




Count_merger6.py
Overview
This script processes gene expression files from a specified input directory, extracts relevant data, and merges it with gene reference and sample mapping information. The final output is a combined dataset with gene expression values for each sample.
Input Files
The script requires three input files:
Gene Expression Files (located in the Count_inputs folder)
Format: Tab-delimited (.txt, .tsv)
Required columns: 
gene_id: Contains gene identifiers.
effective_length: Numeric value representing effective gene length.
expected_count: Numeric count of gene expression.
Gene Reference File (gene_reference.csv)
Format: CSV
Required columns: 
gene_id: Gene identifiers used for merging. Only include protein coding genes here
Symbol: gene symbols corresponding to gene identifiers used in later programs
File ID to Sample ID Mapping File (File_ID_Sample_ID_map.csv)
Format: CSV
Required columns: 
File Id: Identifiers extracted from filenames.
Sample ID: Corresponding sample names or custom short names
Processing Steps
Check for the existence of the Count_inputs directory.
Read the gene reference and mapping files.
Identify gene expression files matching the File Id in the mapping file.
Process each file: 
Extract the gene_id column.
Clean and format gene_id values.
Select only gene_id, effective_length, and expected_count columns.
Merge with the gene reference file.
Insert the corresponding Sample ID.
Use multithreading to parallelize file processing.
Combine processed dataframes column-wise.
Save the final merged dataset.
Output Files
combined_data.csv 
Format: CSV
Contains: 
gene_id: Gene identifiers.
Multiple columns, each representing a different sample's expression data.
Example output: 
gene_id, Sample_1, Sample_2, Sample_3
GENE001, 10.5, 5.2, 8.3
GENE002, 12.0, 4.8, 9.1
Error Handling
If the Count_inputs folder does not exist, an error message is displayed.
If no matching files are found, the script terminates with a message.
If required columns are missing from a file, it is skipped.
Any exceptions during file processing are caught and logged.
Usage
Place the required input files in the correct locations.
Run the script in a Python environment.
The output file combined_data.csv will be generated in the script directory.
Dependencies
os
pandas
concurrent.futures
No additional libraries are required beyond the Python standard library and pandas.
Notes
The script automatically removes any NaN values in the gene_id column.
The output dataset maintains the same gene_id ordering as in the first processed file.
The process is optimized for handling large datasets efficiently using multithreading.

normalize45.py
README
Overview
This script processes RNA-seq gene expression data through multiple steps, including filtering, normalization, transformation, outlier detection, and final formatting for downstream analysis. The output is a cleaned, normalized, and adjusted dataset ready for analysis.
Input Files
The script requires the following input files:
Combined RNA-seq Data (combined_data.csv)
Format: CSV
Contains gene expression values across multiple samples.
Gene Reference File (gene_reference.csv)
Format: CSV
Required columns: 
gene_id: Gene identifiers for filtering protein-coding genes.
Symbol: corresponding genes symbols, will appear as column in certain output files
Sample ID Mapping File (Extracted from combined_data.csv row 2) and generated dynamically during the run-not required to run the program
Used to rename columns and rows appropriately.
Processing Steps
Load Data
Load RNA-seq data from combined_data.csv (or a cached Pickle file for efficiency).
Load the gene reference file.
Filter Protein-Coding Genes
Merge gene expression data with gene reference data to exclude non-protein-coding genes.
Save the output as step1.csv.
Calculate 75th Percentile for Normalization
Compute the 75th percentile of counts per sample.
Calculate the Median Upper Quartile (MUQ).
Save the output as step2_MUQ.csv.
Apply Gene Size Transformation
Transform gene sizes using max(effective_length, 252).
Compute the Global Median Gene Size (MGS).
Save the output as step3_MGS.csv.
Normalize FPKM-UQ Values
Normalize gene expression using FPKM-UQ normalization.
Save the output as step4_fpkm_uq.csv.
Log2 Transformation
Apply log2(FPKM-UQ + 0.01) transformation.
Save the output as step5_log2_fpkm_uq.csv.
Calculate MAD (Median Absolute Deviation) and Identify Outliers
Compute MAD for each sample and determine outliers.
Save results as step6_mad_outliers.csv.
Apply FDR Method for Outlier Detection
Adjust p-values using False Discovery Rate (FDR) correction.
Save the output as step8_outliers.csv.
Rescale Cohorts & Adjust Log2 Values
Exclude outliers and rescale cohorts to a global median of 7.
Save the adjusted data as step14_adj_log2_fpkm_uq.csv.
Replace Negative Log2 Values with Zero
Ensure that all values are non-negative.
Save the output as step15a_replace_negative_with_zero.csv.
Final Adjustments & Output Generation
Save the final adjusted dataset as final_adjusted_log2_fpkm_uq.csv.
Rename Columns Using Sample ID Mapping
Update sample column names in step8_outliers.csv and final_adjusted_log2_fpkm_uq.csv.
Convert Log2 Transformed Data Back to Linear Scale
Save the output as step18_log2_to_linear.csv.
Generate GCT File Format
Convert step18_log2_to_linear.csv into expression.gct for compatibility with GCT-based tools.
Output Files
Dependencies
os
numpy
pandas
scipy.stats
statsmodels
Ensure these libraries are installed before running the script.
Usage
Place the required input files in the correct locations.
Run the script in a Python environment.
Processed outputs will be saved in the script directory.
Notes
The script efficiently handles large datasets using vectorized operations.
The pipeline is optimized for RNA-seq normalization and outlier detection.
Intermediate results are saved for debugging and validation.
The final output is formatted for downstream analysis and visualization.

convertGCT.py
README
Overview
This script converts a CSV file containing gene expression data into a GCT (Gene Cluster Text) format. The resulting GCT file is compatible with tools that require this format for downstream analysis.
Input File
The script requires the following input file:
Step 18 Log2-to-Linear Converted Data (step18_log2_to_linear.csv) -generated during the normalize45.py run in previous step
Format: CSV
Required columns: 
gene_id (will be dropped in the output)
Symbol (gene symbols)
Sample expression values (one column per sample)
Processing Steps
Load Data
Read step18_log2_to_linear.csv.
Drop the gene_id column, as it is not needed in the GCT format.
Initialize GCT Format Headers
First row: #1,2 (identifies the file as GCT format).
Second row: Contains the number of genes and number of samples.
Third row: Column headers with an additional na placeholder between Symbol and sample IDs.
Insert a Blank Column
A blank column (na) is inserted between the Symbol column and sample columns.
Append Gene Expression Data
Gene expression values are retained and written into the GCT format.
Save Output File
The processed data is saved as expression.gct in a tab-delimited format.
Output File
expression.gct 
Format: Tab-delimited text file.
Contains: 
Header rows with metadata.
A properly formatted matrix of gene expression values.
Dependencies
pandas
numpy
Ensure these libraries are installed before running the script.
Usage
Place the required input file (step18_log2_to_linear.csv) in the script directory.
Run the script in a Python environment.
The output file expression.gct will be generated in the script directory.
Notes
The script assumes the first column contains gene symbols (Symbol).
The gene_id column is removed to conform to GCT format specifications.
The blank column (na) is inserted to ensure proper structuring of the GCT file.

GCplotQC.py
README
The main program “GC_plotsQC.py” can be run to automatically execute generate_plot_csv.py and analyze_plot_csv.py. The only inputs required are those needed to run the generate_plot_csv.py program.
generate_plot_csv.py:
Overview
This script processes RNA-seq gene expression data along with GC content and reference values. It merges these datasets, filters invalid values, tracks dropped genes, and generates a cleaned and sorted dataset ready for downstream analysis.
Input Files
The script requires the following input files:
Final Adjusted Log2 FPKM-UQ Data (final_adjusted_log2_fpkm_uq.csv)
Format: CSV
Required columns: 
Symbol: Gene symbols for merging.
Sample expression values (one column per sample).
Gene GC Content Data (Gene_GC.csv)
Format: CSV
Required columns: 
Symbol: Gene symbols for merging.
% GC: Numeric GC content values.
Reference Average Data (Reference_ave.csv)
Format: CSV
Required columns: 
Symbol: Gene symbols for merging.
Reference: Numeric reference expression values.
Processing Steps
Load Data
Read final_adjusted_log2_fpkm_uq.csv, Gene_GC.csv, and Reference_ave.csv.
Drop the gene_id column from final_adjusted_log2_fpkm_uq.csv (if present).
Merge DataFrames
Perform an inner join on the Symbol column to retain only genes present in all three files.
Track Dropped Genes
Identify and save genes missing from any of the input files.
Identify and save genes with invalid numeric values in % GC, Reference, or sample columns.
Save all dropped gene symbols to dropped_genes.txt.
Ensure Numeric Values
Convert % GC, Reference, and sample expression columns to numeric values.
Drop rows where non-numeric values are present.
Save Cleaned and Sorted Data
Retain only relevant columns in the correct order.
Sort the dataset by % GC in ascending order.
Save the cleaned dataset as Plot.csv.
Output Files
Plot.csv
Format: CSV
Contains: 
Symbol: Gene symbols.
% GC: GC content values.
Reference: Reference expression values.
Sample expression values.
Sorted by % GC in ascending order.
dropped_genes.txt
Format: Text file
List of gene symbols that were dropped due to missing or invalid values.
Dependencies
pandas
numpy
os
Ensure these libraries are installed before running the script.
Usage
Place the required input files in the script directory.
Run the script in a Python environment.
The output files Plot.csv and dropped_genes.txt will be generated.
Notes
The script ensures that all merged values are numeric before proceeding.
Genes not found in all three input files are excluded.
The output dataset is sorted by GC content for better visualization.
analyze_plot_csv.py:

Zeroes.py
README
Overview
This script processes gene expression data from Plot.csv to perform spline fitting, calculate the area below a reference curve, detect outliers, and generate visualization plots. The final results include a CSV file with computed areas and a PDF containing the generated plots.
Input Files
The script requires the following input file:
Plot Data (Plot.csv) 
Format: CSV
Required columns: 
% GC: GC content of each gene.
Reference: Reference expression values.
Sample expression values (one column per sample).
Processing Steps
Check for Plot.csv File
Ensures that Plot.csv exists before proceeding.
Terminates with an error message if missing.
Load Data
Reads Plot.csv into a Pandas DataFrame.
Extracts % GC, Reference, and sample expression columns.
Create Output Directory
A folder named plots is created to store generated plots.
Spline Fitting and Area Calculation
Defines 4 knots at evenly spaced GC content percentiles.
Fits separate splines for reference values and each sample.
Calculates the area where the sample expression is below the reference curve.
Saves computed areas in area_below_reference.csv.
Generate and Save Plots
Scatter plots of % GC vs. expression for each sample.
Overlay spline fits for sample and reference.
Saves plots as PNG files in the plots directory.
Outlier Detection
Uses Robust Linear Regression (RLM) to model area values.
Computes residuals and applies False Discovery Rate (FDR) correction.
Identifies outliers based on adjusted p-values (< 0.01).
Updates area_below_reference.csv with outlier status.
Modify Plots to Display Area Data
Loads each generated plot.
Overlays the delta area value as text.
Saves updated plots in the plots directory.
Generate PDF Report
Creates spline_plots.pdf containing all sample plots.
Output Files
area_below_reference.csv
Format: CSV
Contains: 
Sample: Sample name.
Area_Below_Reference: Computed area.
Adjusted P-Value: FDR-corrected significance value.
Outlier: Boolean flag indicating significant deviation.
Plots (plots/)
PNG files for each sample showing spline fits and delta area values.
spline_plots.pdf
A compiled PDF report of all generated plots.
Dependencies
pandas
numpy
matplotlib
scipy
statsmodels
fpdf
Ensure these libraries are installed before running the script.
Usage
Ensure Plot.csv is available in the script directory.
Run the script in a Python environment.
The output files will be generated in the script directory.
Notes
The script calculates areas where sample expression is below the reference.
It uses robust regression and FDR correction to identify outliers.
The output PDF file provides a visual summary of the spline fits.
GC_plotQC.py:

Overview
This script automates the execution of two Python scripts: generate_plot_csv.py and analyze_plot_csv.py. It ensures that Plot.csv is successfully generated before running the analysis.
Process Flow
Generate Plot.csv
Calls generate_plot_csv.py using the Python interpreter from the PDM virtual environment.
Ensures the script runs successfully before proceeding.
Check for Plot.csv Existence
If Plot.csv is found, it proceeds to the next step.
If Plot.csv is missing, it prints an error and stops execution.
Run Analysis on Plot.csv
Calls analyze_plot_csv.py using the same PDM virtual environment.
Ensures the script runs successfully.
Dependencies
Python (managed via PDM virtual environment)
generate_plot_csv.py (must be present in the script directory)
analyze_plot_csv.py (must be present in the script directory)
Output Files
Plot.csv: Generated by generate_plot_csv.py
Analysis results (depends on analyze_plot_csv.py output)
Usage
Ensure PDM is installed and configured.
Place generate_plot_csv.py and analyze_plot_csv.py in the script directory.
Run this script in a Python environment managed by PDM.
Error Handling
If generate_plot_csv.py fails, the script stops execution.
If Plot.csv is not found, analyze_plot_csv.py is not executed.

Zeroes.py
README
Overview
This script analyzes binomial probabilities for gene data, applies the Benjamini-Hochberg false discovery rate (FDR) correction, and generates an updated dataset with raw and adjusted p-values.
Input File
The script requires the following input file:
Zeros Data (Zeros.csv) 
Format: CSV
Required columns: 
Observed_zeros: Number of observed zeros for each gene.
Total_samples: Total number of samples.
Probability: Expected probability of observing zeros.
Processing Steps
Load Data
Reads Zeros.csv into a Pandas DataFrame.
Displays the first few rows to understand its structure.
Calculate Binomial Probabilities
Computes the binomial probability of observing Observed_zeros or more successes in Total_samples trials with the given Probability.
Stores the computed p-values.
Apply Benjamini-Hochberg Correction
Sorts p-values and computes adjusted thresholds.
Ensures adjusted p-values are non-decreasing and do not exceed 1.
Returns p-values in their original order.
Save Results
Adds Raw_P_value and Adjusted_P_value to the dataset.
Saves the updated dataset as Zeros_with_P_values.csv.
Output File
Zeros_with_P_values.csv 
Format: CSV
Contains: 
Observed_zeros: Original observed zero counts.
Total_samples: Number of samples per gene.
Probability: Expected probability of zeros.
Raw_P_value: Unadjusted p-values from the binomial test.
Adjusted_P_value: FDR-adjusted p-values using the Benjamini-Hochberg method.
Dependencies
pandas
numpy
scipy.stats
Ensure these libraries are installed before running the script.
Usage
Ensure Zeros.csv is available in the script directory.
Run the script in a Python environment.
The output file Zeros_with_P_values.csv will be generated in the script directory.
Notes
The script calculates binomial probabilities and applies FDR correction.
It helps identify genes where the observed zero counts are statistically significant.
The adjusted p-values help control for multiple hypothesis testing.
